# -*- coding: utf-8 -*-
"""feature_matching

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vQKqEdhCnYUHt-tHr8AivxjPbdcyI-tm

# Step 3: Feature Matching with Brute-Force and FLANN
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt

def extract_features(image, method):
    """
    Extract keypoints and descriptors from an image using the specified method.

    :param image: Input image
    :param method: 'SIFT', 'SURF', or 'ORB'
    :return: keypoints, descriptors
    """
    if method == 'SIFT':
        detector = cv2.SIFT_create()
    elif method == 'SURF':
        detector = cv2.xfeatures2d.SURF_create()  # Note: This might not work in newer OpenCV versions
    elif method == 'ORB':
        detector = cv2.ORB_create()
    else:
        raise ValueError("Unsupported method. Choose 'SIFT', 'SURF', or 'ORB'.")

    keypoints, descriptors = detector.detectAndCompute(image, None)
    return keypoints, descriptors

def match_features(desc1, desc2, method):
    """
    Match features using either Brute-Force or FLANN.

    :param desc1: Descriptors from the first image
    :param desc2: Descriptors from the second image
    :param method: 'BF' for Brute-Force or 'FLANN' for FLANN-based matcher
    :return: List of good matches
    """
    if method == 'BF':
        matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)
        matches = matcher.match(desc1, desc2)
        good_matches = sorted(matches, key=lambda x: x.distance)
    elif method == 'FLANN':
        FLANN_INDEX_KDTREE = 1
        index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)
        search_params = dict(checks=50)
        matcher = cv2.FlannBasedMatcher(index_params, search_params)
        matches = matcher.knnMatch(desc1, desc2, k=2)
        good_matches = []
        for m, n in matches:
            if m.distance < 0.7 * n.distance:
                good_matches.append(m)
    else:
        raise ValueError("Unsupported method. Choose 'BF' or 'FLANN'.")

    return good_matches

def display_matches(img1, kp1, img2, kp2, matches, title):
    """
    Display matched features between two images.

    :param img1: First input image
    :param kp1: Keypoints from the first image
    :param img2: Second input image
    :param kp2: Keypoints from the second image
    :param matches: List of matches
    :param title: Title for the plot
    """
    img_matches = cv2.drawMatches(img1, kp1, img2, kp2, matches[:10], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)
    plt.figure(figsize=(15, 8))
    plt.imshow(cv2.cvtColor(img_matches, cv2.COLOR_BGR2RGB))
    plt.title(title)
    plt.axis('off')
    plt.show()

# Usage example
img1 = cv2.imread('NEWTON_1.webp')
img2 = cv2.imread('NEWTON_2.webp')
kp1, desc1 = extract_features(img1, 'SIFT')
kp2, desc2 = extract_features(img2, 'SIFT')
good_matches = match_features(desc1, desc2, 'BF')
display_matches(img1, kp1, img2, kp2, good_matches, 'SIFT - BF Matches')

# Display All
if __name__ == "__main__":
    # Load images
    img1 = cv2.imread('NEWTON_1.webp')
    img2 = cv2.imread('NEWTON_2.webp')

    feature_methods = ['SIFT', 'SURF', 'ORB']
    matching_methods = ['BF', 'FLANN']

    for feature_method in feature_methods:
        kp1, desc1 = extract_features(img1, feature_method)
        kp2, desc2 = extract_features(img2, feature_method)

        for matching_method in matching_methods:
            good_matches = match_features(desc1, desc2, matching_method)

            print(f"{feature_method} with {matching_method}:")
            print(f"  Number of good matches: {len(good_matches)}")

            # Display matches
            display_matches(img1, kp1, img2, kp2, good_matches, f'{feature_method} - {matching_method} Matches')